{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import preprocessing\n",
    "from torchvision import transforms as trans\n",
    "import itertools, random, copy, os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "from dataloader import DatasetValidation\n",
    "from models import Backbone\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(id_list, path, k_pairs):\n",
    "    list_pairs = []\n",
    "    for id in id_list:\n",
    "        imgs_list = os.listdir(path+id)\n",
    "        if len(imgs_list)>1:\n",
    "            tmp = list(itertools.combinations(imgs_list, 2))\n",
    "            tmp = [((id+'/'+t[0], id+'/'+t[1]),  True) for t in tmp]\n",
    "            if len(tmp)>=k_pairs:\n",
    "                tmp = random.sample(tmp, k_pairs)\n",
    "            else:\n",
    "                tmp = random.sample(tmp, len(tmp))\n",
    "            list_pairs+=tmp\n",
    "        \n",
    "        copy_id_list = copy.copy(id_list)\n",
    "        copy_id_list.remove(id)\n",
    "        #random_id = random.choice(copy_id_list)\n",
    "        #random_id_imgs = os.listdir('./cropped_img_celeba/'+random_id)\n",
    "        tmp2 = []\n",
    "        for i in range(k_pairs):\n",
    "            random_id = random.choice(copy_id_list)\n",
    "            random_id_imgs = os.listdir(path+random_id)\n",
    "            rch_1 = random.choice(imgs_list)\n",
    "            rch_2 = random.choice(random_id_imgs)\n",
    "            tmp2.append(((id+'/'+rch_1, random_id+'/'+rch_2), False))\n",
    "        list_pairs+=tmp2\n",
    "    return list_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = os.listdir('/data/beybars_id/img_data/cropped_alligned_val/')\n",
    "list_pairs = create_pairs(id_list, '/data/beybars_id/img_data/cropped_alligned_val/', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DatasetValidation(list_pairs, '/data/beybars_id/img_data/cropped_alligned_val/')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['IMG_1_NAME', 'IMG_1', 'IMG_2_NAME', 'IMG_2', 'isSame'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Backbone(50, 0.6, 'ir_se').to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = torch.load('./workspace/steps_models_save/model_2023-02-08-03-39_accuracy:0.9972624999999999_epoch:6_step:153300_None.pth',\n",
    "                      map_location='cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(snapshot['MODEL_STATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nrof_folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [51], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m embeddings_tensor_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(emb_list_1)\n\u001b[1;32m     23\u001b[0m embeddings_tensor_2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mvstack(emb_list_2)\n\u001b[1;32m     24\u001b[0m TPR, TNR, FPR, FNR, accuracy, best_thresholds, tp, tn, fp, fn \u001b[38;5;241m=\u001b[39m evaluate_metrics(embeddings_tensor_1, embeddings_tensor_2,\\\n\u001b[0;32m---> 25\u001b[0m                                                                                  isSame_list, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean_dis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mnrof_folds\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conf\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     27\u001b[0m     thresholds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1.7\u001b[39m, \u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nrof_folds' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(\"Validation...\")\n",
    "emb_list_1 = []\n",
    "emb_list_2 = []\n",
    "isSame_list = []#################################################\n",
    "with torch.no_grad():\n",
    "    for val_batch in val_dataloader:\n",
    "        imgs_1 = val_batch['IMG_1']\n",
    "        imgs_2 = val_batch['IMG_2']\n",
    "        isSame = val_batch['isSame']\n",
    "        imgs_1 = imgs_1.to('cuda:3')\n",
    "        imgs_2 = imgs_2.to('cuda:3')\n",
    "        embeddings_1 = model(imgs_1)\n",
    "        embeddings_2 = model(imgs_2)\n",
    "        embeddings_normed_1 = F.normalize(embeddings_1)\n",
    "        embeddings_normed_2 = F.normalize(embeddings_2)\n",
    "        embeddings_normed_1 = embeddings_normed_1.detach().cpu()\n",
    "        embeddings_normed_2 = embeddings_normed_2.detach().cpu()\n",
    "        emb_list_1.append(embeddings_normed_1)\n",
    "        emb_list_2.append(embeddings_normed_2)\n",
    "        isSame_list+=isSame#################################################\n",
    "    embeddings_tensor_1 = torch.vstack(emb_list_1)\n",
    "    embeddings_tensor_2 = torch.vstack(emb_list_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn, torch\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "def calculate_roc(thresholds, embeddings_tensor_1, embeddings_tensor_2, isSame, sim_metric, nrof_folds):\n",
    "    assert(embeddings_tensor_1.shape[0] == embeddings_tensor_2.shape[0])\n",
    "    assert(embeddings_tensor_1.shape[1] == embeddings_tensor_2.shape[1])\n",
    "\n",
    "    nrof_pairs = len(isSame)\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    #print(nrof_folds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    tprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    tnrs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    fnrs = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    \n",
    "    tp = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    tn = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    fp = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    fn = np.zeros((nrof_folds, nrof_thresholds))\n",
    "    \n",
    "    accuracy_test = np.zeros((nrof_folds))\n",
    "    accuracy_train = np.zeros((nrof_folds, nrof_thresholds)) #################################################\n",
    "    best_thresholds = np.zeros((nrof_folds))\n",
    "    indices = np.arange(nrof_pairs)\n",
    "\n",
    "    if sim_metric=='cosine_sim':\n",
    "        cos_sim = np.dot(embeddings_tensor_1, embeddings_tensor_2)\n",
    "    elif sim_metric=='euclidean_dis':\n",
    "        diff = np.subtract(embeddings_tensor_1, embeddings_tensor_2)\n",
    "        dist = np.square(diff).sum(axis=1)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        # Find the best threshold for the fold\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, _, _, accuracy_train[fold_idx, threshold_idx], _ = calculate_accuracy(threshold, dist[train_set], isSame[train_set])\n",
    "        #best_threshold_index = np.argmax(accuracy_train)\n",
    "        best_threshold_index = np.argmax(accuracy_train[fold_idx])\n",
    "        best_thresholds[fold_idx] = thresholds[best_threshold_index]\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx, threshold_idx], tnrs[fold_idx, threshold_idx],\\\n",
    "            fprs[fold_idx, threshold_idx], fnrs[fold_idx, threshold_idx], _, conf_mat = calculate_accuracy(threshold,\\\n",
    "                                                                                                dist[test_set],\\\n",
    "                                                                                                isSame[test_set])\n",
    "            tp[fold_idx, threshold_idx] = conf_mat[0]\n",
    "            tn[fold_idx, threshold_idx] = conf_mat[1]\n",
    "            fp[fold_idx, threshold_idx] = conf_mat[2]\n",
    "            fn[fold_idx, threshold_idx] = conf_mat[3]\n",
    "            \n",
    "        _, _, _, _, accuracy_test[fold_idx], _ = calculate_accuracy(thresholds[best_threshold_index],\\\n",
    "                                                                            dist[test_set],\\\n",
    "                                                                            isSame[test_set])\n",
    "    tpr = np.mean(tprs, 0)\n",
    "    tnr = np.mean(tnrs, 0)\n",
    "    fpr = np.mean(fprs, 0)\n",
    "    fnr = np.mean(fnrs, 0)\n",
    "    \n",
    "    tp = np.mean(tp, 0)\n",
    "    tn = np.mean(tn, 0)\n",
    "    fp = np.mean(fp, 0)\n",
    "    fn = np.mean(fn, 0)\n",
    "    \n",
    "    return tpr, tnr, fpr, fnr, accuracy_test, best_thresholds, tp, tn, fp, fn\n",
    "\n",
    "\n",
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    predict_issame_bool = predict_issame.clone().detach().numpy()\n",
    "\n",
    "    # print(predict_issame[:5])\n",
    "    # print()\n",
    "    # print(actual_issame[:5])\n",
    "    TP = np.sum(np.logical_and(predict_issame_bool, actual_issame))\n",
    "    FP = np.sum(np.logical_and(predict_issame_bool, np.logical_not(actual_issame)))\n",
    "    TN = np.sum(np.logical_and(np.logical_not(predict_issame_bool), np.logical_not(actual_issame)))\n",
    "    FN = np.sum(np.logical_and(np.logical_not(predict_issame_bool), actual_issame))\n",
    "    \n",
    "    TPR = 0 if (TP + FN == 0) else float(TP) / float(TP + FN)\n",
    "    TNR = 0 if (TN + FP == 0) else float(TN) / float(TN + FP)\n",
    "    FPR = 0 if (FP + TN == 0) else float(FP) / float(FP + TN)\n",
    "    FNR = 0 if (FN + TP == 0) else float(FN) / float(FN + TP)\n",
    "    acc = float(TP + TN)/dist.shape[0]\n",
    "    return TPR, TNR, FPR, FNR, acc, (TP, TN, FP, FN)\n",
    "\n",
    "\n",
    "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10):\n",
    "    '''\n",
    "    Copy from [insightface](https://github.com/deepinsight/insightface)\n",
    "    :param thresholds:\n",
    "    :param embeddings1:\n",
    "    :param embeddings2:\n",
    "    :param actual_issame:\n",
    "    :param far_target:\n",
    "    :param nrof_folds:\n",
    "    :return:\n",
    "    '''\n",
    "    assert (embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert (embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
    "\n",
    "    val = np.zeros(nrof_folds)\n",
    "    far = np.zeros(nrof_folds)\n",
    "\n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff), 1)\n",
    "    indices = np.arange(nrof_pairs)\n",
    "\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "\n",
    "        # Find the threshold that gives FAR = far_target\n",
    "        far_train = np.zeros(nrof_thresholds)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
    "        if np.max(far_train) >= far_target:\n",
    "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
    "            threshold = f(far_target)\n",
    "        else:\n",
    "            threshold = 0.0\n",
    "\n",
    "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
    "\n",
    "    val_mean = np.mean(val)\n",
    "    far_mean = np.mean(far)\n",
    "    val_std = np.std(val)\n",
    "    return val_mean, val_std, far_mean\n",
    "\n",
    "\n",
    "def calculate_val_far(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    torch.tensor(a, dtype=torch.bool)\n",
    "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    n_same = np.sum(actual_issame)\n",
    "    n_diff = np.sum(np.logical_not(actual_issame))\n",
    "    val = float(true_accept) / float(n_same)\n",
    "    far = float(false_accept) / float(n_diff)\n",
    "    return val, far\n",
    "\n",
    "\n",
    "def evaluate_metrics(embeddings_tensor_1, embeddings_tensor_2, isSame, sim_metric, nrof_folds=5):\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    tpr, tnr, fpr, fnr, accuracy_test, best_thresholds, tp, tn, fp, fn = calculate_roc(thresholds,\\\n",
    "                                                                                   embeddings_tensor_1,\\\n",
    "                                                                                   embeddings_tensor_2,\\\n",
    "                                                                                   np.asarray(isSame),\\\n",
    "                                                                                   sim_metric,\\\n",
    "                                                                                   nrof_folds=nrof_folds\n",
    "                                                                                  )\n",
    "    return tpr, tnr, fpr, fnr, accuracy_test, best_thresholds, tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR, TNR, FPR, FNR, accuracy, best_thresholds, tp, tn, fp, fn = evaluate_metrics(embeddings_tensor_1, embeddings_tensor_2,\\\n",
    "                                                                                     isSame_list, 'euclidean_dis', 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:1.47,\n",
      " precision:0.9996902806726768,\n",
      " recall:0.9952166666666666,\n",
      " fraud_det:0.9996916666666666\n",
      "\n",
      "threshold:1.48,\n",
      " precision:0.9996233647753998,\n",
      " recall:0.9952833333333334,\n",
      " fraud_det:0.999625\n",
      "\n",
      "threshold:1.48,\n",
      " precision:0.9996233647753998,\n",
      " recall:0.9952833333333334,\n",
      " fraud_det:0.999625\n",
      "\n",
      "0.0018355908013004598\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0, 4, 0.01)\n",
    "for thr in best_thresholds:\n",
    "    indx=np.where(thresholds == thr)\n",
    "    ind = indx[0].item()\n",
    "    precision = tp[ind]/(tp[ind]+fp[ind])\n",
    "    recall = tp[ind]/(tp[ind]+fn[ind])\n",
    "    fraud = tn[ind]/(tn[ind]+fp[ind])\n",
    "    print('threshold:{},\\n precision:{},\\n recall:{},\\n fraud_det:{}'.format(thr, precision, recall, fraud))\n",
    "    print()\n",
    "from sklearn import metrics\n",
    "auc_roc = metrics.auc(TPR, FPR)\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.66658334e-05, 1.66658334e-05, 2.49995834e-05, 3.33333334e-05,\n",
       "       3.33333334e-05, 3.33333334e-05, 4.16670834e-05, 4.16670834e-05,\n",
       "       5.83341668e-05, 9.16687502e-05, 1.08335417e-04, 1.41668334e-04,\n",
       "       1.50001250e-04, 1.91669167e-04, 2.50002917e-04, 3.08336250e-04,\n",
       "       3.75001667e-04, 4.83334584e-04, 5.66666251e-04, 7.00002085e-04,\n",
       "       8.16669168e-04, 1.01666750e-03, 1.20833209e-03, 1.46666709e-03,\n",
       "       1.75833417e-03, 2.16666500e-03, 2.70000000e-03, 3.26666751e-03,\n",
       "       3.97499751e-03, 4.97499918e-03, 6.10833001e-03, 7.46666793e-03,\n",
       "       9.08333418e-03, 1.08083279e-02, 1.28166504e-02, 1.49083109e-02,\n",
       "       1.75333117e-02, 2.03249750e-02, 2.35416342e-02, 2.74916450e-02,\n",
       "       3.21416246e-02, 3.72166176e-02, 4.29499538e-02, 4.97582947e-02,\n",
       "       5.69332988e-02, 6.51082980e-02, 7.38583018e-02, 8.42833093e-02,\n",
       "       9.51833218e-02, 1.07124993e-01, 1.20125001e-01, 1.33650008e-01,\n",
       "       1.48658346e-01, 1.64758337e-01, 1.82366683e-01, 2.00891674e-01,\n",
       "       2.19999992e-01, 2.40058344e-01, 2.61341698e-01, 2.84400011e-01,\n",
       "       3.08366636e-01, 3.32041591e-01, 3.57133252e-01, 3.82749927e-01,\n",
       "       4.08666605e-01, 4.34424942e-01, 4.61508286e-01, 4.88224936e-01,\n",
       "       5.14366615e-01, 5.41583309e-01, 5.68041651e-01, 5.94983348e-01,\n",
       "       6.21483351e-01, 6.47625028e-01, 6.72900029e-01, 6.96900007e-01,\n",
       "       7.20558345e-01, 7.43425011e-01, 7.65124992e-01, 7.85291678e-01,\n",
       "       8.05366686e-01, 8.23458397e-01, 8.41166713e-01, 8.57533373e-01,\n",
       "       8.72525021e-01, 8.86175021e-01, 8.98933356e-01, 9.10700010e-01,\n",
       "       9.21083320e-01, 9.31074979e-01, 9.39591637e-01, 9.47083303e-01,\n",
       "       9.54533309e-01, 9.60833309e-01, 9.66183316e-01, 9.71274980e-01,\n",
       "       9.75516641e-01, 9.79216649e-01, 9.82549995e-01, 9.85299990e-01,\n",
       "       9.87999989e-01, 9.90141650e-01, 9.91766650e-01, 9.93308319e-01,\n",
       "       9.94549990e-01, 9.95583327e-01, 9.96416661e-01, 9.97158330e-01,\n",
       "       9.97591659e-01, 9.98066660e-01, 9.98408325e-01, 9.98716660e-01,\n",
       "       9.98974997e-01, 9.99241665e-01, 9.99383329e-01, 9.99533331e-01,\n",
       "       9.99649997e-01, 9.99724998e-01, 9.99808333e-01, 9.99858333e-01,\n",
       "       9.99891666e-01, 9.99908333e-01, 9.99925000e-01, 9.99949999e-01,\n",
       "       9.99966667e-01, 9.99983333e-01, 9.99983333e-01, 9.99983333e-01,\n",
       "       9.99983333e-01, 9.99991667e-01, 9.99991667e-01, 9.99991667e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 6.66670834e-05, 6.66670834e-05, 6.66670834e-05,\n",
       "       6.66670834e-05, 8.33337501e-05, 8.33337501e-05, 1.08333750e-04,\n",
       "       1.58334167e-04, 2.74997500e-04, 3.91664167e-04, 6.16660418e-04,\n",
       "       9.08323751e-04, 1.25832292e-03, 1.87499334e-03, 2.69999417e-03,\n",
       "       3.75833334e-03, 5.03333042e-03, 6.59999376e-03, 8.63333085e-03,\n",
       "       1.10916659e-02, 1.43916717e-02, 1.84666792e-02, 2.35750121e-02,\n",
       "       2.93416842e-02, 3.62750380e-02, 4.43333509e-02, 5.34750105e-02,\n",
       "       6.39333443e-02, 7.58750060e-02, 8.91500251e-02, 1.03825038e-01,\n",
       "       1.19891727e-01, 1.37041730e-01, 1.55708414e-01, 1.75150086e-01,\n",
       "       1.95708432e-01, 2.17675114e-01, 2.40950094e-01, 2.64766776e-01,\n",
       "       2.88766791e-01, 3.13341796e-01, 3.38625118e-01, 3.62908434e-01,\n",
       "       3.87725090e-01, 4.13191772e-01, 4.38541806e-01, 4.63641817e-01,\n",
       "       4.88566831e-01, 5.12183490e-01, 5.35358474e-01, 5.58041805e-01,\n",
       "       5.80591810e-01, 6.02566793e-01, 6.23558449e-01, 6.43741771e-01,\n",
       "       6.63275120e-01, 6.82383451e-01, 7.00891798e-01, 7.18025148e-01,\n",
       "       7.34125137e-01, 7.50016782e-01, 7.64333458e-01, 7.78466770e-01,\n",
       "       7.91491773e-01, 8.03875103e-01, 8.15866775e-01, 8.27141776e-01,\n",
       "       8.37433452e-01, 8.47416779e-01, 8.56266764e-01, 8.64941753e-01,\n",
       "       8.73058419e-01, 8.80758421e-01, 8.87725102e-01, 8.94583423e-01,\n",
       "       9.01108422e-01, 9.07283432e-01, 9.12766762e-01, 9.18575094e-01,\n",
       "       9.23908419e-01, 9.28425089e-01, 9.32591751e-01, 9.36500084e-01,\n",
       "       9.40266743e-01, 9.43975065e-01, 9.47116724e-01, 9.50075057e-01,\n",
       "       9.53100052e-01, 9.55866721e-01, 9.58366710e-01, 9.61025045e-01,\n",
       "       9.63125044e-01, 9.65116702e-01, 9.67383371e-01, 9.69358362e-01,\n",
       "       9.70875023e-01, 9.72425021e-01, 9.73883355e-01, 9.75233352e-01,\n",
       "       9.76725017e-01, 9.78033350e-01, 9.79391692e-01, 9.80475022e-01,\n",
       "       9.81575021e-01, 9.82500015e-01, 9.83316687e-01, 9.84225017e-01,\n",
       "       9.84816687e-01, 9.85658352e-01, 9.86316685e-01, 9.86975022e-01,\n",
       "       9.87558352e-01, 9.88083349e-01, 9.88616682e-01, 9.89141684e-01,\n",
       "       9.89591682e-01, 9.90008351e-01, 9.90433349e-01, 9.90783346e-01,\n",
       "       9.91125012e-01, 9.91450012e-01, 9.91758348e-01, 9.92000017e-01,\n",
       "       9.92225021e-01, 9.92516688e-01, 9.92691686e-01, 9.92941686e-01,\n",
       "       9.93100019e-01, 9.93341683e-01, 9.93525017e-01, 9.93675018e-01,\n",
       "       9.93866686e-01, 9.94000020e-01, 9.94091687e-01, 9.94191685e-01,\n",
       "       9.94300016e-01, 9.94383349e-01, 9.94466682e-01, 9.94591681e-01,\n",
       "       9.94691678e-01, 9.94766677e-01, 9.94858343e-01, 9.94933344e-01,\n",
       "       9.94975012e-01, 9.95033344e-01, 9.95091677e-01, 9.95216676e-01,\n",
       "       9.95283342e-01, 9.95358342e-01, 9.95383342e-01, 9.95408343e-01,\n",
       "       9.95475010e-01, 9.95500011e-01, 9.95541679e-01, 9.95558345e-01,\n",
       "       9.95575011e-01, 9.95608344e-01, 9.95658345e-01, 9.95683345e-01,\n",
       "       9.95716679e-01, 9.95741679e-01, 9.95783346e-01, 9.95808346e-01,\n",
       "       9.95825013e-01, 9.95841680e-01, 9.95883346e-01, 9.95883346e-01,\n",
       "       9.95908346e-01, 9.95925012e-01, 9.95933345e-01, 9.95933345e-01,\n",
       "       9.95933345e-01, 9.95950012e-01, 9.95966678e-01, 9.95983344e-01,\n",
       "       9.95991677e-01, 9.96000011e-01, 9.96008344e-01, 9.96016677e-01,\n",
       "       9.96050011e-01, 9.96066678e-01, 9.96066678e-01, 9.96108343e-01,\n",
       "       9.96125010e-01, 9.96150010e-01, 9.96183343e-01, 9.96208344e-01,\n",
       "       9.96258344e-01, 9.96358343e-01, 9.96483342e-01, 9.96541675e-01,\n",
       "       9.96650009e-01, 9.96858343e-01, 9.97100009e-01, 9.97400006e-01,\n",
       "       9.97608339e-01, 9.97850005e-01, 9.98091669e-01, 9.98408337e-01,\n",
       "       9.98658335e-01, 9.98841667e-01, 9.99066667e-01, 9.99216669e-01,\n",
       "       9.99366669e-01, 9.99508333e-01, 9.99574998e-01, 9.99649998e-01,\n",
       "       9.99708333e-01, 9.99783332e-01, 9.99841665e-01, 9.99849997e-01,\n",
       "       9.99891665e-01, 9.99916665e-01, 9.99924999e-01, 9.99941666e-01,\n",
       "       9.99958333e-01, 9.99966667e-01, 9.99983334e-01, 9.99983334e-01,\n",
       "       9.99983334e-01, 9.99983334e-01, 9.99983334e-01, 9.99983334e-01,\n",
       "       9.99983334e-01, 9.99991667e-01, 9.99991667e-01, 9.99991667e-01,\n",
       "       9.99991667e-01, 9.99991667e-01, 9.99991667e-01, 9.99991667e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981644091986995"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc=metrics.auc(FPR,TPR)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(FPR, TPR, color='darkorange',\n",
    "         label='ROC  (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(' ROC-')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTrain(Dataset):\n",
    "    def __init__(self, list_imgs, img_dir, labels):\n",
    "        self.list_imgs = list_imgs\n",
    "        self.img_dir = img_dir\n",
    "        self.labels = labels\n",
    "        self.transform = trans.Compose([trans.ToTensor(),\n",
    "                                        trans.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_filename_1 = self.img_dir+self.list_imgs[index]\n",
    "        cv_img_1 = cv2.imread(img_filename_1)\n",
    "        cv_img_1 = cv2.cvtColor(cv_img_1, cv2.COLOR_BGR2RGB)\n",
    "        cv_img_1 = self.transform(cv_img_1)\n",
    "        label = self.labels[index]\n",
    "\n",
    "        output = {\n",
    "            'IMG_1_NAME':self.list_imgs[index],\n",
    "            'IMG_1':cv_img_1,\n",
    "            'LABEL':label\n",
    "            }\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_list(path):\n",
    "    tmp = os.listdir(path)\n",
    "    list_imgs = []\n",
    "    labels = []\n",
    "    for t in tmp:\n",
    "        tmp_tmp = os.listdir(path+t)\n",
    "        for tt in tmp_tmp:\n",
    "            #if os.path.isdir(path+t+'/'+tt):\n",
    "            list_imgs.append(t+'/'+tt)\n",
    "            labels.append(t)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels_new = le.fit_transform(labels)\n",
    "    num_calsses = len(le.classes_)\n",
    "    return list_imgs, labels_new, num_calsses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_imgs, labels_new, num_calsses = create_train_list('/data/dev_5/beybars/face_rec/personal_arcFace/data/cropped_2/cropped_alligned_train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1924"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_calsses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88462"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88462"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetTrain(list_imgs, '/data/dev_5/beybars/face_rec/personal_arcFace/data/cropped_2/cropped_alligned_train/', labels_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ds, batch_size=95, shuffle=False)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100%25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5991,  0.6142,  0.3017,  0.2814, -0.9649],\n",
      "        [-1.4914,  0.7996,  0.0508, -1.3391,  1.1146],\n",
      "        [-2.7230,  0.3357, -1.2446, -2.6732, -0.0811]], requires_grad=True)\n",
      "tensor([2, 0, 0])\n",
      "tensor(2.8458, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "tensor([[ 0.0336,  0.1129, -0.2507,  0.0810,  0.0233],\n",
      "        [-0.3223,  0.1089,  0.0515,  0.0128,  0.1492],\n",
      "        [-0.3254,  0.1700,  0.0350,  0.0084,  0.1120]])\n",
      "tensor(2.8458, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print()\n",
    "print(input.grad)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.linear1(x)\n",
    "        print(x.shape)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        print(x.shape)\n",
    "        x = self.softmax(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 100])\n",
      "torch.Size([200, 200])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39697/380898572.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 10])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tinymodel(torch.rand(200,100))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            torch.nn.Linear(100, 200),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(200, 10),\n",
    "            torch.nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.seq(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0874, 0.1135, 0.0810,  ..., 0.1005, 0.0996, 0.1065],\n",
       "        [0.0927, 0.1172, 0.0981,  ..., 0.0893, 0.1007, 0.0988],\n",
       "        [0.0833, 0.1020, 0.0844,  ..., 0.0965, 0.1103, 0.1072],\n",
       "        ...,\n",
       "        [0.0937, 0.1191, 0.0927,  ..., 0.0998, 0.0970, 0.1067],\n",
       "        [0.0914, 0.1074, 0.0878,  ..., 0.1008, 0.0971, 0.0998],\n",
       "        [0.1039, 0.1057, 0.0859,  ..., 0.1032, 0.0921, 0.1066]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tinymodel(torch.rand(200,100))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq.0.weight torch.Size([200, 100])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0067,  0.0833,  0.0607,  ..., -0.0700, -0.0266,  0.0903],\n",
      "        [-0.0087, -0.0766,  0.0153,  ...,  0.0362,  0.0976, -0.0320],\n",
      "        [-0.0274,  0.0902,  0.0409,  ...,  0.0529, -0.0202, -0.0013],\n",
      "        ...,\n",
      "        [-0.0455, -0.0669,  0.0239,  ...,  0.0474,  0.0215, -0.0670],\n",
      "        [ 0.0186, -0.0251,  0.0194,  ...,  0.0096,  0.0849, -0.0561],\n",
      "        [ 0.0588, -0.0748, -0.0754,  ..., -0.0988, -0.0120,  0.0899]],\n",
      "       requires_grad=True)\n",
      "\n",
      "seq.0.bias torch.Size([200])\n",
      "Parameter containing:\n",
      "tensor([ 0.0884, -0.0443, -0.0094, -0.0099, -0.0586,  0.0126, -0.0594, -0.0893,\n",
      "        -0.0407, -0.0190,  0.0260, -0.0984,  0.0128, -0.0581, -0.0061,  0.0115,\n",
      "        -0.0408,  0.0348, -0.0031,  0.0544,  0.0057, -0.0303, -0.0416, -0.0494,\n",
      "        -0.0440,  0.0569, -0.0948,  0.0326, -0.0449, -0.0026, -0.0381,  0.0156,\n",
      "         0.0473,  0.0523, -0.0989,  0.0098,  0.0385, -0.0263, -0.0054,  0.0696,\n",
      "        -0.0301, -0.0453,  0.0963, -0.0185, -0.0152, -0.0014,  0.0316, -0.0480,\n",
      "         0.0239, -0.0047, -0.0573,  0.0789,  0.0442, -0.0536,  0.0837,  0.0752,\n",
      "         0.0388, -0.0178, -0.0806,  0.0514, -0.0959,  0.0825,  0.0726, -0.0460,\n",
      "        -0.0640,  0.0614, -0.0710, -0.0907, -0.0303,  0.0672, -0.0427,  0.0063,\n",
      "         0.0336,  0.0908, -0.0860,  0.0539, -0.0898, -0.0214,  0.0252, -0.0096,\n",
      "         0.0298, -0.0730, -0.0069, -0.0670,  0.0117, -0.0458, -0.0496, -0.0900,\n",
      "        -0.0464, -0.0980, -0.0651, -0.0205,  0.0525,  0.0012, -0.0774,  0.0825,\n",
      "        -0.0862,  0.0161, -0.0949,  0.0560,  0.0508,  0.0538,  0.0015,  0.0119,\n",
      "        -0.0610, -0.0513,  0.0593,  0.0109, -0.0367,  0.0678,  0.0157,  0.0082,\n",
      "         0.0574,  0.0867,  0.0969,  0.0822,  0.0505,  0.0404,  0.0063, -0.0980,\n",
      "         0.0664,  0.0526,  0.0049,  0.0938, -0.0488, -0.0421,  0.0373, -0.0846,\n",
      "         0.0839,  0.0079,  0.0005,  0.0828, -0.0667, -0.0955, -0.0702,  0.0033,\n",
      "         0.0226,  0.0853,  0.0358, -0.0502, -0.0783,  0.0591,  0.0430,  0.0357,\n",
      "         0.0939, -0.0986,  0.0893, -0.0675, -0.0393, -0.0451,  0.0588, -0.0038,\n",
      "         0.0494, -0.0949, -0.0146, -0.0092,  0.0003, -0.0468,  0.0390,  0.0555,\n",
      "         0.0850, -0.0673, -0.0027,  0.0502, -0.0566, -0.0989,  0.0198,  0.0481,\n",
      "        -0.0194,  0.0358, -0.0743,  0.0771, -0.0101, -0.0611, -0.0220,  0.0363,\n",
      "         0.0830, -0.0134, -0.0349, -0.0408, -0.0614,  0.0474, -0.0807,  0.0495,\n",
      "         0.0999,  0.0444,  0.0076,  0.0311,  0.0657,  0.0541,  0.0403,  0.0062,\n",
      "         0.0294, -0.0918,  0.0318, -0.0806, -0.0081, -0.0101,  0.0214,  0.0156],\n",
      "       requires_grad=True)\n",
      "\n",
      "seq.2.weight torch.Size([10, 200])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0332,  0.0564,  0.0598,  ...,  0.0572,  0.0637,  0.0258],\n",
      "        [-0.0275, -0.0306,  0.0402,  ...,  0.0190, -0.0232,  0.0566],\n",
      "        [-0.0095,  0.0197,  0.0426,  ...,  0.0089,  0.0476,  0.0636],\n",
      "        ...,\n",
      "        [ 0.0626,  0.0244,  0.0141,  ..., -0.0107,  0.0381, -0.0184],\n",
      "        [ 0.0112, -0.0241, -0.0007,  ..., -0.0226, -0.0323,  0.0338],\n",
      "        [-0.0637, -0.0417,  0.0459,  ...,  0.0216, -0.0363,  0.0703]],\n",
      "       requires_grad=True)\n",
      "\n",
      "seq.2.bias torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([-0.0187, -0.0280,  0.0661, -0.0557, -0.0591, -0.0120, -0.0620, -0.0238,\n",
      "        -0.0061, -0.0491], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, p in tinymodel.named_parameters():\n",
    "    print(n, p.shape)\n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.1\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(tinymodel.parameters(), lr=0.1, momentum=0.9)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [192], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer\u001b[39m.\u001b[39;49mstate_dict()[\u001b[39m'\u001b[39;49m\u001b[39mstate\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "optimizer.state_dict()['state'][0]['momentum_buffer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.01,\n",
       "  'momentum': 0.9,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False,\n",
       "  'maximize': False,\n",
       "  'foreach': None,\n",
       "  'differentiable': False,\n",
       "  'params': [0, 1, 2, 3]}]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()['param_groups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0793, -0.0847, -0.0111, -0.0102,  0.0048,  0.0402, -0.0271,  0.0024,\n",
       "         0.0522,  0.0632], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinymodel.seq[0].weight[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0041,  0.0878,  0.0599, -0.0899,  0.0134,  0.0371,  0.0643, -0.0292,\n",
      "         0.0439, -0.0090], grad_fn=<SliceBackward0>)\n",
      "tensor(2.2159, grad_fn=<NllLossBackward0>)\n",
      "tensor([-3.5434e-04,  6.7762e-05,  1.5425e-04, -4.2033e-04, -1.6688e-04,\n",
      "         2.8904e-04, -2.3796e-05, -3.2430e-04,  2.9211e-04,  2.8192e-04])\n",
      "\n",
      "tensor([ 0.0041,  0.0877,  0.0599, -0.0898,  0.0134,  0.0370,  0.0643, -0.0292,\n",
      "         0.0439, -0.0090], grad_fn=<SliceBackward0>)\n",
      "tensor(2.2152, grad_fn=<NllLossBackward0>)\n",
      "tensor([-3.5538e-04,  6.8213e-05,  1.5478e-04, -4.2378e-04, -1.6746e-04,\n",
      "         2.8419e-04, -2.5302e-05, -3.2423e-04,  2.9604e-04,  2.8737e-04])\n",
      "\n",
      "tensor([ 0.0042,  0.0877,  0.0599, -0.0898,  0.0134,  0.0370,  0.0643, -0.0291,\n",
      "         0.0438, -0.0091], grad_fn=<SliceBackward0>)\n",
      "tensor(2.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor([-3.5739e-04,  6.9128e-05,  1.5578e-04, -4.3047e-04, -1.6858e-04,\n",
      "         2.7479e-04, -2.8144e-05, -3.2412e-04,  3.0358e-04,  2.9789e-04])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(200, 100, requires_grad=True)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "target = torch.empty(200, dtype=torch.long).random_(5)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    optimizer.zero_grad()\n",
    "    output = tinymodel(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    print(tinymodel.seq[0].weight[0,:10])\n",
    "    print(loss)\n",
    "    #print(tinymodel.seq[0].weight[0,:10])\n",
    "    print(tinymodel.seq[0].weight.grad[0,:10])\n",
    "    print()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.Tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.Tensor([1,2,3])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.zeros((1))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=(a==b).sum()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c+d).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = os.listdir('/data/dev_5/beybars/face_rec/personal_arcFace/data/cropped_2/cropped_alligned_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in ad:\n",
    "    listPath = os.listdir('/data/dev_5/beybars/face_rec/personal_arcFace/data/cropped_2/cropped_alligned_train'+'/'+a)\n",
    "    for aa in listPath:\n",
    "        if os.path.isdir('/data/dev_5/beybars/face_rec/personal_arcFace/data/cropped_2/cropped_alligned_train'+'/'+a+'/'+aa):\n",
    "            print('/data/dev_5/beybars/face_rec/personal_arcFace/data/cropped_2/cropped_alligned_train'+'/'+a+'/'+aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('data/celeba/train/8659/187912.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[119, 126, 119],\n",
       "        [121, 128, 121],\n",
       "        [107, 114, 111],\n",
       "        ...,\n",
       "        [134, 106, 105],\n",
       "        [134, 107, 103],\n",
       "        [134, 107, 103]],\n",
       "\n",
       "       [[122, 130, 123],\n",
       "        [ 84,  91,  86],\n",
       "        [ 74,  83,  80],\n",
       "        ...,\n",
       "        [135, 107, 106],\n",
       "        [134, 107, 103],\n",
       "        [134, 107, 103]],\n",
       "\n",
       "       [[ 71,  83,  77],\n",
       "        [ 67,  79,  73],\n",
       "        [116, 127, 124],\n",
       "        ...,\n",
       "        [132, 107, 105],\n",
       "        [134, 107, 103],\n",
       "        [134, 107, 103]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 90, 106, 129],\n",
       "        [103, 120, 141],\n",
       "        [107, 124, 143],\n",
       "        ...,\n",
       "        [148, 151, 165],\n",
       "        [145, 151, 164],\n",
       "        [144, 150, 163]],\n",
       "\n",
       "       [[ 84, 103, 124],\n",
       "        [ 99, 118, 139],\n",
       "        [103, 123, 141],\n",
       "        ...,\n",
       "        [149, 152, 166],\n",
       "        [146, 151, 166],\n",
       "        [145, 150, 165]],\n",
       "\n",
       "       [[ 88, 107, 128],\n",
       "        [102, 121, 142],\n",
       "        [105, 125, 143],\n",
       "        ...,\n",
       "        [150, 153, 167],\n",
       "        [146, 151, 166],\n",
       "        [145, 150, 165]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "labels_new = le.fit_transform(['23','23', '564', '564', '555', '564'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,1,2,3], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand((5,512))\n",
    "t2 = torch.rand((5,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.subtract(t1, t2)\n",
    "diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(85.7096)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(diff)[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([85.7096, 85.7546, 83.2996, 90.2393, 88.7972])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = np.square(diff).sum(axis=1)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([[0, 1], [0, 5]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.logical_and(np.array([True, True, False]), np.array([True, False, False])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_484827/1936017203.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  a = torch.tensor(a, dtype=torch.bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(a, dtype=torch.bool)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0, 0, 0, 0, 0], dtype=torch.bool)\n",
    "a = a.numpy()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([True, True, False, False, False])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.logical_and(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 65, 35, 75]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3] + [65,35,75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_152 = Backbone(152, 0.5, 'ir_se')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_50 = Backbone(50, 0.5, 'ir_se')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer.0.weight Parameter containing:\n",
      "tensor([[[[-0.1499, -0.1135, -0.1518],\n",
      "          [-0.1037,  0.1264, -0.1843],\n",
      "          [-0.0067, -0.0064, -0.0406]],\n",
      "\n",
      "         [[ 0.0662, -0.1525, -0.1288],\n",
      "          [ 0.0385,  0.0722, -0.1723],\n",
      "          [ 0.0490,  0.1560, -0.1194]],\n",
      "\n",
      "         [[ 0.1589, -0.1903,  0.0717],\n",
      "          [ 0.1408, -0.0576, -0.1536],\n",
      "          [ 0.0274, -0.0644,  0.0039]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1731, -0.1853,  0.0162],\n",
      "          [ 0.0660,  0.1052,  0.1485],\n",
      "          [-0.1000, -0.1134, -0.1515]],\n",
      "\n",
      "         [[ 0.1476, -0.1245, -0.1483],\n",
      "          [-0.0646,  0.0594,  0.0222],\n",
      "          [-0.1542,  0.0461, -0.0857]],\n",
      "\n",
      "         [[ 0.1836,  0.1339,  0.1828],\n",
      "          [-0.0229,  0.0636, -0.0589],\n",
      "          [-0.1645,  0.1896,  0.0641]]],\n",
      "\n",
      "\n",
      "        [[[-0.1671, -0.1235,  0.1093],\n",
      "          [ 0.0375,  0.0527,  0.0293],\n",
      "          [ 0.1553, -0.1402, -0.0672]],\n",
      "\n",
      "         [[-0.0559,  0.0889, -0.0155],\n",
      "          [-0.1256, -0.0691, -0.0757],\n",
      "          [ 0.1631, -0.0647,  0.0551]],\n",
      "\n",
      "         [[ 0.1793, -0.0220, -0.0166],\n",
      "          [-0.1298,  0.1389,  0.0627],\n",
      "          [-0.1895, -0.1136,  0.0780]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1630, -0.0429,  0.1878],\n",
      "          [-0.1535,  0.1747,  0.1872],\n",
      "          [-0.0113, -0.0194, -0.1309]],\n",
      "\n",
      "         [[-0.0794,  0.0985, -0.0945],\n",
      "          [-0.0008, -0.0882, -0.1337],\n",
      "          [ 0.1578,  0.1249, -0.0015]],\n",
      "\n",
      "         [[-0.1460,  0.0325,  0.1625],\n",
      "          [-0.0429, -0.0548,  0.1666],\n",
      "          [ 0.1438,  0.1741, -0.1369]]],\n",
      "\n",
      "\n",
      "        [[[-0.1456, -0.0359,  0.1263],\n",
      "          [ 0.0172, -0.1739, -0.1451],\n",
      "          [-0.0642, -0.1243, -0.1852]],\n",
      "\n",
      "         [[ 0.1084, -0.0466, -0.1221],\n",
      "          [-0.0257, -0.1730, -0.0806],\n",
      "          [ 0.1361, -0.0776,  0.1922]],\n",
      "\n",
      "         [[ 0.1252, -0.1623, -0.0130],\n",
      "          [-0.0322, -0.1895, -0.1889],\n",
      "          [ 0.0702, -0.0674,  0.0779]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1470,  0.0474, -0.0644],\n",
      "          [-0.1687, -0.1648,  0.1406],\n",
      "          [-0.1494, -0.0874, -0.1331]],\n",
      "\n",
      "         [[-0.0906,  0.0422, -0.1267],\n",
      "          [ 0.0509, -0.1483, -0.0564],\n",
      "          [-0.0485,  0.1848, -0.1042]],\n",
      "\n",
      "         [[ 0.1413, -0.0513, -0.1577],\n",
      "          [ 0.1020, -0.1323, -0.1407],\n",
      "          [ 0.0724, -0.0224,  0.0314]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_152.named_parameters():\n",
    "    print(name, param)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.1499, -0.1135, -0.1518],\n",
       "          [-0.1037,  0.1264, -0.1843],\n",
       "          [-0.0067, -0.0064, -0.0406]],\n",
       "\n",
       "         [[ 0.0662, -0.1525, -0.1288],\n",
       "          [ 0.0385,  0.0722, -0.1723],\n",
       "          [ 0.0490,  0.1560, -0.1194]],\n",
       "\n",
       "         [[ 0.1589, -0.1903,  0.0717],\n",
       "          [ 0.1408, -0.0576, -0.1536],\n",
       "          [ 0.0274, -0.0644,  0.0039]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1731, -0.1853,  0.0162],\n",
       "          [ 0.0660,  0.1052,  0.1485],\n",
       "          [-0.1000, -0.1134, -0.1515]],\n",
       "\n",
       "         [[ 0.1476, -0.1245, -0.1483],\n",
       "          [-0.0646,  0.0594,  0.0222],\n",
       "          [-0.1542,  0.0461, -0.0857]],\n",
       "\n",
       "         [[ 0.1836,  0.1339,  0.1828],\n",
       "          [-0.0229,  0.0636, -0.0589],\n",
       "          [-0.1645,  0.1896,  0.0641]]],\n",
       "\n",
       "\n",
       "        [[[-0.1671, -0.1235,  0.1093],\n",
       "          [ 0.0375,  0.0527,  0.0293],\n",
       "          [ 0.1553, -0.1402, -0.0672]],\n",
       "\n",
       "         [[-0.0559,  0.0889, -0.0155],\n",
       "          [-0.1256, -0.0691, -0.0757],\n",
       "          [ 0.1631, -0.0647,  0.0551]],\n",
       "\n",
       "         [[ 0.1793, -0.0220, -0.0166],\n",
       "          [-0.1298,  0.1389,  0.0627],\n",
       "          [-0.1895, -0.1136,  0.0780]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.1630, -0.0429,  0.1878],\n",
       "          [-0.1535,  0.1747,  0.1872],\n",
       "          [-0.0113, -0.0194, -0.1309]],\n",
       "\n",
       "         [[-0.0794,  0.0985, -0.0945],\n",
       "          [-0.0008, -0.0882, -0.1337],\n",
       "          [ 0.1578,  0.1249, -0.0015]],\n",
       "\n",
       "         [[-0.1460,  0.0325,  0.1625],\n",
       "          [-0.0429, -0.0548,  0.1666],\n",
       "          [ 0.1438,  0.1741, -0.1369]]],\n",
       "\n",
       "\n",
       "        [[[-0.1456, -0.0359,  0.1263],\n",
       "          [ 0.0172, -0.1739, -0.1451],\n",
       "          [-0.0642, -0.1243, -0.1852]],\n",
       "\n",
       "         [[ 0.1084, -0.0466, -0.1221],\n",
       "          [-0.0257, -0.1730, -0.0806],\n",
       "          [ 0.1361, -0.0776,  0.1922]],\n",
       "\n",
       "         [[ 0.1252, -0.1623, -0.0130],\n",
       "          [-0.0322, -0.1895, -0.1889],\n",
       "          [ 0.0702, -0.0674,  0.0779]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1470,  0.0474, -0.0644],\n",
       "          [-0.1687, -0.1648,  0.1406],\n",
       "          [-0.1494, -0.0874, -0.1331]],\n",
       "\n",
       "         [[-0.0906,  0.0422, -0.1267],\n",
       "          [ 0.0509, -0.1483, -0.0564],\n",
       "          [-0.0485,  0.1848, -0.1042]],\n",
       "\n",
       "         [[ 0.1413, -0.0513, -0.1577],\n",
       "          [ 0.1020, -0.1323, -0.1407],\n",
       "          [ 0.0724, -0.0224,  0.0314]]]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0775,  0.0518,  0.1201],\n",
       "          [-0.1530, -0.0839,  0.0477],\n",
       "          [-0.0605, -0.0236, -0.0553]],\n",
       "\n",
       "         [[ 0.0307, -0.1082,  0.0978],\n",
       "          [-0.0131, -0.1763,  0.1709],\n",
       "          [-0.0135,  0.0840, -0.0292]],\n",
       "\n",
       "         [[ 0.0024,  0.1840, -0.1290],\n",
       "          [ 0.0498, -0.0859, -0.1329],\n",
       "          [ 0.1045,  0.1757,  0.0237]]],\n",
       "\n",
       "\n",
       "        [[[-0.1487,  0.0574, -0.0408],\n",
       "          [ 0.1684, -0.1633,  0.0081],\n",
       "          [-0.0961, -0.1461,  0.1166]],\n",
       "\n",
       "         [[-0.1534, -0.1761,  0.1261],\n",
       "          [-0.0159,  0.1332,  0.0497],\n",
       "          [ 0.1055,  0.1008,  0.1867]],\n",
       "\n",
       "         [[ 0.1787, -0.0421,  0.1237],\n",
       "          [ 0.0158, -0.0924, -0.1394],\n",
       "          [ 0.1139,  0.0824, -0.0793]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1650,  0.0663,  0.0392],\n",
       "          [ 0.1577, -0.1458,  0.1376],\n",
       "          [-0.1283,  0.1307,  0.0449]],\n",
       "\n",
       "         [[-0.1066,  0.0124,  0.1273],\n",
       "          [ 0.1054, -0.1147, -0.1232],\n",
       "          [-0.0076, -0.1397,  0.1256]],\n",
       "\n",
       "         [[-0.1066,  0.1648,  0.0626],\n",
       "          [ 0.1119,  0.0515,  0.0897],\n",
       "          [-0.1285,  0.1752, -0.0257]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.1158,  0.0671,  0.0721],\n",
       "          [-0.0324,  0.0814, -0.1472],\n",
       "          [-0.0002,  0.0485, -0.1919]],\n",
       "\n",
       "         [[ 0.1908,  0.0273,  0.0999],\n",
       "          [ 0.0083, -0.1234, -0.1782],\n",
       "          [ 0.0997, -0.0478,  0.0283]],\n",
       "\n",
       "         [[-0.0182,  0.0081, -0.1571],\n",
       "          [ 0.0275, -0.0318, -0.0854],\n",
       "          [ 0.0526, -0.1367, -0.1627]]],\n",
       "\n",
       "\n",
       "        [[[-0.1001, -0.0974,  0.0830],\n",
       "          [-0.0065, -0.0184,  0.0869],\n",
       "          [-0.1019, -0.0321,  0.1226]],\n",
       "\n",
       "         [[-0.0801, -0.1642, -0.1412],\n",
       "          [-0.0721, -0.0618, -0.1308],\n",
       "          [ 0.1246,  0.0051,  0.1129]],\n",
       "\n",
       "         [[ 0.1704, -0.0543, -0.0827],\n",
       "          [-0.0453, -0.0393, -0.1666],\n",
       "          [ 0.0854,  0.1632,  0.1615]]],\n",
       "\n",
       "\n",
       "        [[[-0.1364, -0.0629, -0.0917],\n",
       "          [ 0.1558,  0.0920,  0.0769],\n",
       "          [-0.0858,  0.0658, -0.0020]],\n",
       "\n",
       "         [[-0.1210,  0.1673, -0.1210],\n",
       "          [ 0.0321, -0.0155, -0.1421],\n",
       "          [-0.0118, -0.0201, -0.0025]],\n",
       "\n",
       "         [[ 0.0477,  0.0175,  0.0542],\n",
       "          [-0.0643, -0.0571, -0.1528],\n",
       "          [-0.1260,  0.1180, -0.0390]]]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05487116, 0.3571734 , 0.70541702, 0.78444567, 0.481968  ],\n",
       "       [0.58076222, 0.51203435, 0.50082611, 0.66668407, 0.73384853],\n",
       "       [0.30198868, 0.61321013, 0.06083147, 0.42012282, 0.79811782],\n",
       "       [0.96800602, 0.01877541, 0.12136246, 0.40466663, 0.90564885],\n",
       "       [0.75113543, 0.31090119, 0.31540748, 0.76741288, 0.61756497]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = np.random.rand(5,5)\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, 0, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(tst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ids = os.listdir('/data/beybars_id/img_data/cropped_alligned/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ids = os.listdir('/data/beybars_id/img_data/cropped_alligned_val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = random.sample(list_ids, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'920425401700'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['970122400843',\n",
       " '910906402167',\n",
       " '920924451195',\n",
       " '910716302871',\n",
       " '801018301978',\n",
       " '810218300123',\n",
       " '000928500682',\n",
       " '031001501440',\n",
       " '790102300423']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ids[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/beybars_id/img_data/cropped_alligned_val/920425401700'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = '/data/beybars_id/img_data/cropped_alligned/920425401700/'\n",
    "dst = '/data/beybars_id/img_data/cropped_alligned_val/'\n",
    "shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100000/100000 [04:09<00:00, 401.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(val_ids):\n",
    "    src = '/data/beybars_id/img_data/cropped_alligned/'+i+'/'\n",
    "    dst = '/data/beybars_id/img_data/cropped_alligned_extra/'\n",
    "    shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.nn.Parameter(torch.FloatTensor(813500, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([813500, 512])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "from models import Backbone, Arcface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Backbone(50, 0.6, 'ir_se').to()\n",
    "head = Arcface(embedding_size=512, classnum=self.class_num).to(conf.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 2, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09,\n",
       "       1.1 , 1.11, 1.12, 1.13, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19, 1.2 ,\n",
       "       1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3 , 1.31,\n",
       "       1.32, 1.33, 1.34, 1.35, 1.36, 1.37, 1.38, 1.39, 1.4 , 1.41, 1.42,\n",
       "       1.43, 1.44, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5 , 1.51, 1.52, 1.53,\n",
       "       1.54, 1.55, 1.56, 1.57, 1.58, 1.59, 1.6 , 1.61, 1.62, 1.63, 1.64,\n",
       "       1.65, 1.66, 1.67, 1.68, 1.69, 1.7 , 1.71, 1.72, 1.73, 1.74, 1.75,\n",
       "       1.76, 1.77, 1.78, 1.79, 1.8 , 1.81, 1.82, 1.83, 1.84, 1.85, 1.86,\n",
       "       1.87, 1.88, 1.89, 1.9 , 1.91, 1.92, 1.93, 1.94, 1.95, 1.96, 1.97,\n",
       "       1.98, 1.99])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx=np.where(thresholds == 1.47)\n",
    "indx[0].item()\n",
    "# ind = indx[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "551ffafacf1c435d455694253e8083a24e9824fcef8ea36e6955e47cea1a95b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
